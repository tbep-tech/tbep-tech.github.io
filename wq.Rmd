---
title: "Get EPCHC Data, Tidy it Up & Perform TBEP Annual WQ Assessment"
author: "Ed Sherwood <esherwood@tbep.org>"
date: "February 4, 2019"
output: 
  html_document: 
    code_folding: hide
    toc: yes
    toc_float: yes
---

Original: [esherwoo77/pull_epc_data:pull_epc_data.Rmd](https://github.com/esherwoo77/pull_epc_data/blob/master/pull_epc_data.Rmd)

```{r setup, include=FALSE}
# libraries
require(tidyverse)
require(lubridate)
require(readxl)
require(curl)
require(leaflet)
require(rmarkdown)
require(here) # gets consistent path based on *.Rproj
require(glue) # easy string creation
library(tools)
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F)

# variables
download_latest_epchc <- FALSE

# paths
# here(): set path based on root of repo where *.Rproj is found
epchc_xlsx    <- here("data-raw/epchc.xlsx")
epcdata_rdata <- here("data-raw/epcdata.RData")

# set Google Drive folder to where sync'd
user <- Sys.info()[["user"]]
dir_gdrive <- case_when(
  user == "Marcus" ~ "C:/Users/Marcus.SCCWRP2K/Desktop/Google Drive/tbep-tech",
  user == "bbest" ~ "/Users/bbest/Gdrive Ecoquants/projects/tbep-tech")

# test paths
test_xlsx <- file.path(dir_gdrive, "data/wq/2018_Results_Updated.xls")
stopifnot(file.exists(test_xlsx))
```

## TODO

- Shiny app:
  - slider to change thresholds and see results
  - p


## Code to Download EPCHC Dataset
```{r epchc_download}
#library(tbeptools)
#get_epchc_wq(epchc_xlsx)

#URL of EPCHC's long-term dataset in Excel Spreadsheet format
epchc_url <- "ftp://ftp.epchc.org/EPC_ERM_FTP/WQM_Reports/RWMDataSpreadsheet_ThroughCurrentReportMonth.xlsx"

if (!file.exists(epchc_xlsx) | download_latest_epchc){
  # download data from EPCHC's ftp site
  tmp_xlsx <- tempfile(fileext = "xlsx")
  download.file(url = epchc_url, destfile = tmp_xlsx, method = "libcurl", mode = "wb") # 23.2 MB
  
  is_latest <- md5sum(epchc_xlsx) == md5sum(tmp_xlsx)
  if (!is_latest){
    file.copy(tmp_xlsx, epchc_xlsx, overwrite=T)
  }
}

# TODO: for Travis updating: if (is_latest) return() # no need to update
```

## Correctly Import EPCHC xlsx Data File into R

```{r epchc_import}
#EPC data column name file
epcnames <- readLines("./data-raw/epchc_column_names.csv")  ### WHAT HAPPENS IF COLUMNS SHIFT??

#EPC sites within Tampa Bay used for the Annual TBEP WQ Assessment
epcsites <- c(6, 7, 8, 44, 52, 55, 70, 71, 73, 80, 36, 38, 40, 41, 46, 47, 50, 51, 60, 63, 64, 65, 66, 67, 68, 9,               11, 81, 84, 13, 14, 32, 33, 16, 19, 28, 82, 23, 24, 25, 90, 91, 92, 93, 95)
#Station Lists by Bay Segment
otb_stations <- c(36, 38, 40, 41, 46, 47, 50, 51, 60, 63, 64, 65, 66, 67, 68)
hb_stations <- c(6, 7, 8, 44, 52, 55, 70, 71, 73, 80)
mtb_stations <- c(9, 11, 81, 84, 13, 14, 32, 33, 16, 19, 28, 82)
ltb_stations <- c(23, 24, 25, 90, 91, 92, 93, 95)
#Short Bay Segment Names
bay_segments = c("OTB", "HB", "MTB", "LTB")

#Data frame that lists bay segment specific management targets + low and high magnitude exceedance thresholds
targets <- data.frame(bay_segment = c("OTB", "HB", "MTB", "LTB"),
                           name = c("Old Tampa Bay", "Hillsborough Bay", "Middle Tampa Bay", "Lower Tampa Bay"),
                           chla_target = c(8.5, 13.2, 7.4, 4.6),
                           chla_smallex = c(8.9, 14.1, 7.9, 4.8),
                           chla_thresh = c(9.3, 15.0, 8.5, 5.1),
                           la_target = c(0.83, 1.58, 0.83, 0.63),
                           la_smallex = c(0.86, 1.63, 0.87, 0.66),
                           la_thresh = c(0.88, 1.67, 0.91, 0.68))

#Import the raw dataset into R

### THIS SEEMS A BIT DANGEROUS TO ME - IS THERE A BETTER WAY TO MAKE SURE THAT THE COLUMNS DIDNT SHIFT. WHY NOT READ IN COLUMN HEADERS?

epcdata <- read_xlsx("./data-raw/epchc.xlsx", 
                     sheet="RWMDataSpreadsheet", 
                     col_types = c("numeric", "numeric", "text", "text", "text", "text", 
                                   "numeric", "numeric", "text", "numeric", "numeric", 
                                   "text", "date", "text", "numeric", "text", "text", 
                                   "numeric", "numeric", "numeric", "numeric", "text", 
                                   "text", "text", "numeric", "text", "numeric", "text", 
                                   "numeric", "text", "numeric", "text", "numeric", 
                                   "text", "numeric", "text", "numeric", "text", 
                                   "numeric", "text", "numeric", "text", "numeric", 
                                   "text", "numeric", "text", "numeric", "text", 
                                   "numeric", "text", "numeric", "text", "numeric", 
                                   "text", "numeric", "text", "numeric", "text", 
                                   "numeric", "text", "numeric", "text", "numeric", 
                                   "text", "numeric", "text", "text", "text", "text", 
                                   "text", "text", "text", "text", "text", "text", 
                                   "text", "text", "text", "text", "text", "text", 
                                   "text", "text", "text", "text", "text", "text", 
                                   "text", "text", "text", "text", "text", "text",
                                   "text", "text", "text", "text", "text", "text", 
                                   "text", "text", "text", "text", "text", "text", 
                                   "text", "text", "text", "text", "text", "text", 
                                   "text", "text", "text", "text", "text", "text", 
                                   "text", "text", "text", "text", "text", "text",
                                   "text", "text", "text", "text", "text", "text",
                                   "text", "text", "text", "text", "text", "text", 
                                   "text", "text", "text", "text", "text", "text",
                                   "text", "text", "text", "text", "text", "text",
                                   "text", "text", "text", "text", "text", "text",
                                   "text", "text", "text", "text", "text", "text",
                                   "text", "text", "text"),
                     col_names = epcnames, 
                     skip=1, na="")
save(epcdata, file = epcdata_rdata, compress = 'xz')
#load('./data-raw/epcdata.Rdata')
```


```{r ecphc_validate}
#Filter entire EPCHC dataset
wqdata <- epcdata %>%                   ### USE OF PIPE OPERATOR - DPLYR FUNCTIONS? LOOKS LIKE IT ENDS WITH CLOSED PARENS
          select(StationNumber,
                 Latitude,
                 Longitude,
                 SampleTime,
                 Total_Depth_m,
                 Sample_Depth_m,
                 Secchi_Depth_m,
                 Secchi_Q,
                 Chlorophyll_a_uncorr_ugL,
                 Chlorophyll_a_uncorr_Q) %>% 
          mutate(epchc_station = as.numeric(StationNumber),
                 sd_m = as.numeric(Secchi_Depth_m),
                 sd_check = as.numeric((Total_Depth_m*3.2809)-(Secchi_Depth_m*3.2809)),
                 chla = as.numeric(Chlorophyll_a_uncorr_ugL),
                 yr = year(SampleTime),
                 mo = month(SampleTime)) %>% 
          filter(epchc_station %in% epcsites)

#Assign NAs to VOB secchi disk depths or secchis <0.5ft from bottom -- Janicki protocols
wqdata <- within(wqdata, sd_m[Secchi_Q == ">"] <- NA)
wqdata <- within(wqdata, sd_m[sd_check < 0.5] <- NA)

wqdata$bay_segment <- ifelse(wqdata$epchc_station %in% hb_stations, "HB",                        ### SUBSETTING IFELSE STATEMENTS
                             ifelse(wqdata$epchc_station %in% otb_stations, "OTB",
                                    ifelse(wqdata$epchc_station %in% mtb_stations, "MTB",
                                           ifelse(wqdata$epchc_station %in% ltb_stations, "LTB",NA))))


#Display station locations
wqsites <- wqdata %>% 
           select(epchc_station, Latitude, Longitude) %>% 
           unique()                                                   ### WHAT IS THIS - DOES IT SELECT ONLY UNIQUE FULL ROWS?

map <- leaflet(wqsites) %>%                                            ### LOOKS LIKE THIS MAPS LOCATION OF STATIONS IN WQSITES - CAN WE IMPROVE TO PLOT COLOR CODED AVERAGES
              addProviderTiles(providers$CartoDB.Positron) %>% 
              addCircleMarkers(~Longitude, ~Latitude,
                               radius = 6,
                               color = 'black',
                               stroke = FALSE,
                               opacity = 0.8,
                               popup = ~as.character(paste('EPC Station:', epchc_station)), 
                               group = 'Water quality') %>% 
              addLayersControl(overlayGroups = c('Water quality'),
                               options = layersControlOptions(collapsed = FALSE))
map
```

```{r calculate_means}                                          
#Generate annual averages for each bay segment
tbdata <-subset(wqdata, bay_segment != "MTB")                   ### DROPS MTB HERE - DEALS WITH IT LATER 
tbmonchla <- tbdata %>% 
               select(yr, mo, bay_segment, chla) %>%
               drop_na() %>%
               group_by(yr, mo, bay_segment) %>%
               summarise(mean_chla = mean(chla))
tbyrchla <- tbmonchla %>% 
               select(bay_segment, yr, mean_chla) %>% 
               drop_na() %>% 
               group_by(bay_segment, yr) %>% 
               summarise(mean_chla = mean(mean_chla))
  
tbmonsdm <- tbdata %>% 
               select(yr, mo, bay_segment, sd_m) %>%
               drop_na() %>%
               group_by(yr, mo, bay_segment) %>%
               summarise(mean_sdm = mean(sd_m))

tbyrsdm <- tbmonsdm %>% 
               select(bay_segment, yr, mean_sdm) %>% 
               drop_na() %>% 
               group_by(bay_segment, yr) %>% 
               summarise(mean_sdm = mean(mean_sdm))

#Process MTB data using weighted averages of 3 subsegments
mtbdata <- subset(wqdata, bay_segment == "MTB")
mtbdata$baysegment <- ifelse(mtbdata$epchc_station %in% c(9, 11, 81, 84), "MT1",
                             ifelse(mtbdata$epchc_station %in% c(13, 14, 32, 33), "MT2",
                                    ifelse(mtbdata$epchc_station %in% c(16, 19, 28, 82), "MT3", NA)))
mtbmonthlychla <- mtbdata %>%
                select(yr, mo, baysegment, chla) %>% 
                drop_na() %>% 
                group_by(yr, mo, baysegment) %>% 
                summarise(mean_chla = mean(chla))
mtbmonchla <- mtbmonthlychla

mtbmonthlysdm <- mtbdata %>%                                  ### SECCHI DISK
                select(yr, mo, baysegment, sd_m) %>% 
                drop_na() %>% 
                group_by(yr, mo, baysegment) %>% 
                summarise(mean_sd_m = mean(sd_m))
mtbmonsdm <- mtbmonthlysdm

mtbmonchla$chla <- ifelse(mtbmonchla$baysegment=="MT1", mtbmonchla$mean_chla*2108.7,                  ### AREA WEIGHTED ?
                        ifelse(mtbmonchla$baysegment=="MT2", mtbmonchla$mean_chla*1041.9,
                               ifelse(mtbmonchla$baysegment=="MT3", mtbmonchla$mean_chla*974.6, NA)))
mtbmonsdm$sdm <- ifelse(mtbmonsdm$baysegment=="MT1", mtbmonsdm$mean_sd_m*2108.7,
                        ifelse(mtbmonsdm$baysegment=="MT2", mtbmonsdm$mean_sd_m*1041.9,
                               ifelse(mtbmonsdm$baysegment=="MT3", mtbmonsdm$mean_sd_m*974.6, NA)))
mtbmoyrchla <- mtbmonchla %>%
                select(yr, mo, baysegment, chla) %>% 
                drop_na() %>% 
                group_by(yr, mo) %>% 
                summarise(sum_chla = sum(chla)) %>% 
                mutate(mean_chla = sum_chla/4125.2,              ### WEIGHTED AVERAGE MONTHLY
                       bay_segment ="MTB") 

mtbyrchla <- mtbmoyrchla %>%
                select(yr, mean_chla) %>% 
                drop_na() %>% 
                group_by(yr) %>% 
                summarise(mean_chla = mean(mean_chla)) %>% 
                mutate(bay_segment = "MTB")                   ###AVERAGE OF MONTHLY AREA WEIGHTED
  

mtbmoyrsdm <- mtbmonsdm %>%
                select(yr, mo, baysegment, sdm) %>% 
                drop_na() %>% 
                group_by(yr, mo) %>% 
                summarise(sum_sdm = sum(sdm)) %>% 
                mutate(mean_sdm = sum_sdm/4125.2,            ### WEIGHTED AVERAGE sd
                       bay_segment ="MTB")

mtbyrsdm <- mtbmoyrsdm %>%
                select(yr, mean_sdm) %>% 
                drop_na() %>% 
                group_by(yr) %>% 
                summarise(mean_sdm = mean(mean_sdm)) %>% 
                mutate(bay_segment = "MTB")

#Put it all together
chladata <- bind_rows(tbyrchla, mtbyrchla)
chlamodata <- bind_rows(tbmonchla, mtbmoyrchla)
sdmdata <- bind_rows(tbyrsdm, mtbyrsdm)
sdmmodata <- bind_rows(tbmonsdm, mtbmoyrsdm)


### I BELIEVE THE BELOW ARE GEISSON FACTORS FOR sd TO CALCULATE % LIGHT AVAILABILITY
sdmdata$mean_la <- ifelse(sdmdata$bay_segment =="OTB", 1.49/sdmdata$mean_sdm,
                             ifelse(sdmdata$bay_segment =="HB", 1.61/sdmdata$mean_sdm,
                                    ifelse(sdmdata$bay_segment =="MTB", 1.49/sdmdata$mean_sdm,
                                           ifelse(sdmdata$bay_segment =="LTB", 1.84/sdmdata$mean_sdm,NA))))
```

## Plot Mean Annual Chl-a Values by Bay Segment {.tabset}
```{r plot_chla_annual_averages, results='asis'}
cols <- c("Annual Mean"="red", "Management Target"="blue", "Regulatory Threshold"="blue", "Small Mag. Exceedance"="blue", "Large Mag. Exceedance"="blue")
for (i in seq_along(bay_segments)) {
   chlaplot <- chladata %>%
                 filter(bay_segment == bay_segments[i] & yr<2019) %>%                           ###   LOOP TO PLOT BY BAYSEGMENT
                 ggplot(aes(x=yr)) +                                                            ###   SEE GARY'S NOTES ON REQUESTED IMPROVEMENTS
                   geom_point(aes(y=mean_chla, colour="Annual Mean"), size=3) +
                   geom_line(aes(y=mean_chla, colour="Annual Mean"), size=0.75) +
                   geom_hline(data=targets, aes(yintercept = as.numeric(chla_thresh[i]),        ###    DO THEY WANT TO ADD OTHER REFERENCE LINES?
                                                colour="Regulatory Threshold")) +
                   ggtitle(paste(targets$name[i])) +
                   geom_text(data=targets, parse = TRUE,
                             aes(1973, as.numeric(chla_thresh[i]),
                                 label = paste(chla_thresh[i],"~ mu * g%.%L^{-1}"),            ### NOT SURE WHAT g%.%L IS BUT ITS A LABEL
                                 hjust = 0.2, vjust = -0.3)) +
                   ylab(expression("Mean Annual Chlorophyll-a ("~ mu * "g\u00B7L"^-1 *")")) +
                   xlab("") +
                   scale_x_continuous(breaks=seq(1973,2019,by=1),                                   ### IS THERE A WAY TO AUTOMATE THIS SO WE DONT HAVE TO MANUALLY SCALE AXIS?
                                      labels=c(1973, rep("",3), 1977, rep("",3), 1981, rep("",3),
                                               1985, rep("",3), 1989, rep("",3), 1993, rep("",3),
                                               1997, rep("",3), 2001, rep("",3), 2005, rep("",3),
                                               2009, rep("",3), 2013, rep("",3), 2017, rep("",2)),
                                      expand = c(0.035,0)) +
                   theme(plot.title = element_text(hjust = 0.5),
                         panel.grid.minor=element_blank(),
                         panel.grid.major=element_blank(),
                         legend.position = c(0.88, 0.95),
                         legend.background = element_rect(fill=NA)) +
                   scale_colour_manual(name="", values = cols,
                                       labels=c("Annual Mean", "Regulatory Threshold"))
   cat("###", paste(targets$name[i]), "\n")
   print(chlaplot)
   cat("\n\n")
} 
```

## Plot Mean Annual Light Attenuation Values by Bay Segment {.tabset}
```{r plot_la_annual_averages, results='asis'}
for (i in seq_along(bay_segments)) {
    sdmplot <- sdmdata %>%
                 filter(bay_segment == bay_segments[i] & yr<2019) %>% 
                 ggplot(aes(x=yr)) + 
                   geom_point(aes(y=mean_la, colour="Annual Mean"), size=3) +
                   geom_line(aes(y=mean_la, colour="Annual Mean"), size=0.75) +
                   geom_hline(data=targets, aes(yintercept = as.numeric(la_target[i]),
                                                colour="Management Target")) +
                   ggtitle(paste(targets$name[i])) +
                   geom_text(data=targets, parse = T,
                             aes(1973, as.numeric(la_target[i]),
                                 label = paste(la_target[i],"~m","^{-1}"),
                                 hjust = 0.3, vjust = -0.3)) +
                   ylab(expression("Mean Annual Light Attenuation (m  " ^-1 *")")) +
                   xlab("") +
                   scale_x_continuous(breaks=seq(1973,2019,by=1),
                                      labels=c(1973, rep("",3), 1977, rep("",3), 1981, rep("",3),
                                               1985, rep("",3), 1989, rep("",3), 1993, rep("",3),
                                               1997, rep("",3), 2001, rep("",3), 2005, rep("",3),
                                               2009, rep("",3), 2013, rep("",3), 2017, rep("",2)),
                                      expand = c(0.035,0)) +
                   theme(plot.title = element_text(hjust = 0.5),
                         panel.grid.minor=element_blank(),
                         panel.grid.major=element_blank(),
                         legend.position = c(0.88, 0.95),
                         legend.background = element_rect(fill=NA)) +
                   scale_colour_manual(name="", values = cols,
                                       labels=c("Annual Mean", "Management Target"))
   cat("###", paste(targets$name[i]), "\n")  
   print(sdmplot)
   cat("\n\n")
} 

```
#### NEED TO USE THE FILES BELOW TO GENERATE THE COLOR CODED TABLE OF RESULTS

## Export Annual Values as a Tidy CSV File
Export final datasets to csv files in 'data-processed' folder.
```{r epchc_export_tidy_data}
write.csv(chladata, file = "./data-processed/TB_Chla_Annual_Means.csv")
write.csv(chlamodata, file = "./data-processed/TB_Chla_Monthly_means.csv")
write.csv(sdmdata, file = "./data-processed/TB_Secchi_Annual_Means.csv")
write.csv(sdmmodata, file = "./data-processed/TB_Secchi_Monthly_means.csv")
```

## Colorized Table

Now let's produce a color coded table similar to that found in [tbep-tech:data/wq/TBEP_01_19_2018_**Decision_Matrix_Update**.pdf](https://drive.google.com/open?id=1NGq0VzaPv1_uxgoDkprVTAndSuBygSuq)
  
![](/Users/bbest/github/tbep-tech.github.io/img/decision-matrix_color-table-snip.png)

except we'll include the actual values and color code cells along a gradient using the new [**gt**](https://github.com/rstudio/gt) R package.

```{r}
#library(formattable)
library(gt)

colorize_fld <- function(gtbl, fld, pal=c("red", "yellow", "green"), digits=1){
  #browser()
  gtbl %>% 
    data_color(
      #columns = vars(fld), 
      columns = fld, 
      colors = scales::col_numeric(
        palette = pal,
        domain =  gtbl[[fld]])) %>% 
    fmt_number(
      #columns = vars(fld),
      columns = fld,
      decimals = 1) 
}

colorize_tbl <- function(gtbl, exclude_cols="Year", pal=c("red", "yellow", "green"), digits=1){
  flds <- setdiff(names(gtbl), exclude_cols)
  for (fld in flds){
    gtbl <- colorize_fld(gtbl, fld, pal, digits)
  }
  gtbl
}

read_csv(here("data-processed/TB_Chla_Annual_Means.csv")) %>% 
  select(-X1) %>% 
  #View()
  spread(bay_segment, mean_chla) %>% 
  rename(Year=yr) %>% #,
  gt() %>% 
  colorize_tbl()
```
